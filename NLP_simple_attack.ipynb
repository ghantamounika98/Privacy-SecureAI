{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PGVk1kdNKrn"
      },
      "source": [
        "# Design a Simple Attack System For NLP Domain Using TextAttack Library\n",
        "\n",
        "In this work, **we aim to design a simple Adversarial Example (AE) generator for a standard text classification task in the black-box setting. **The system will be evaluated and its results will be visualized to get a better undestanding about such attack systems in the Natural Language Processig (NLP) domain.\n",
        "\n",
        "Generating adversarial examples for textual data is not quite as straightforward as it is for image data due to the discrete nature of the text context. The AE generator approaches in NLP range from character-level to sentence-level techniques where the word-level methods demonstrate their superiority compared to other approaches. **This work has concentrated on word-level attacks where substituting important words to fool the target model is the most common technique. **Our method aims to implement a word substitution method using the following components:\n",
        "* The method employs a lexical database of English to find synonyms for each important word in order to perform word-substituting operations. This can be called the transformation step.\n",
        "* Moreover, we need to restrict substitutions to preserve the linguistic characteristics (such as semantic, syntactic, grammatical) of the original text and source language. This step is referred to as constraints.    \n",
        "\n",
        "---\n",
        "\n",
        "We employ the TextAttack library (https://github.com/QData/TextAttack) to design our attack system. TextAttack is a python framework for adversarial attacks, data augmentation, and model training in the NLP domain. TextAttack formulates an attack as consisting of four components:\n",
        "\n",
        "### Goal Function\n",
        "a goal function that determines whether the attack is successful in terms of the model outputs.\n",
        "* Examples: untargeted classification, targeted classification, non-overlapping output\n",
        "\n",
        "### Constraints\n",
        "constraints which determine if a perturbation is valid with respect to the original input\n",
        "* Examples: maximum word embedding distance, part-of-speech consistency, grammar checker, minimum sentence encoding cosine similarity\n",
        "\n",
        "### Transformation\n",
        "a transformation that generates potential modifications given an input\n",
        "* Examples: word embedding word swap, thesaurus word swap, homoglyph character substitution.\n",
        "\n",
        "### Search Method\n",
        "a search method that successively queries the model and selects promising perturbations from a set of transformations.\n",
        "* Examples: greedy with word importance ranking, beam search, genetic algorithm.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtXqmP5Ehn9h"
      },
      "source": [
        "#Library Steup\n",
        "We need to install the TextAttack library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hU10wohNLrw"
      },
      "outputs": [],
      "source": [
        "!pip3 install textattack[tensorflow]\n",
        "\n",
        "#after installation, we should restart the runtime and then reinstall the textattack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbwNcCgya4zo"
      },
      "source": [
        "# Creating Goal Function, Target Model, And Dataset\n",
        "We are performing an untargeted attack on a classification model. The goal is to fool a victim model to predict a different label than the true label for an input sample. As victom model, we employ BERT (https://arxiv.org/abs/1810.04805), a state-of-the-art transformer-based neural model, trained for news classification on the AG News dataset. There are several pretrained models in [HuggingFace Model Hub](https://huggingface.co/textattack) that we can employ for our attacking aim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLwnRoqk7sOm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "80a739244f134c5c8bee831f0a52d024",
            "b9c4e64bdf4a41d6980ffc28d0a29e41",
            "14dda15a98044e46930667bd7afdbc50",
            "3c3acc886a174238a39bcc2f54df10d1",
            "3a702163f10645669e73a1c9661e8a19",
            "97bde56b86f148e3afa13c94e573a38f",
            "27c7200c9dae4da38494406e808d38ae",
            "082700d6e12843ce8eb952f2991db734",
            "a88ef7b99d924a60bbc3f15e5d227bb3",
            "b7ea639972b84778b545998ea617ce11",
            "d84883c78de14be4aca6972fd5dd43a3"
          ]
        },
        "outputId": "6c5a51b5-0ded-45fc-9870-1ed0779332e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "WARNING:datasets.builder:Using custom data configuration default\n",
            "WARNING:datasets.builder:Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80a739244f134c5c8bee831f0a52d024"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mag_news\u001b[0m, split \u001b[94mtest\u001b[0m.\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
        "\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"textattack/bert-base-uncased-ag-news\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    \"textattack/bert-base-uncased-ag-news\")\n",
        "\n",
        "model_wrapper = ...\n",
        "\n",
        "# Create the goal function using the model\n",
        "from textattack.goal_functions import UntargetedClassification\n",
        "goal_function = ...\n",
        "\n",
        "# Import the dataset\n",
        "from textattack.datasets import HuggingFaceDataset\n",
        "dataset = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCiJ6eDPeOE-"
      },
      "source": [
        "# Using Our Transformation\n",
        "\n",
        "A transformation module generates potential modifications given an input sample to generate a related adversarial example in order to fool the target model.\n",
        "\n",
        "In this step, we design a simple transformation component based on the synonym-based substitution method. To do so, we utilize the \"wordnet\" database to obtain various meaningful synonyms for each important word achieved by a search method in the next steps. WordNet is a lexical database of semantic relations between words in more than 200 languages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjQ81yhInl0-"
      },
      "outputs": [],
      "source": [
        "from textattack.transformations import WordSwap\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "\n",
        "class Synonym_Substitution(WordSwap):\n",
        "  \"\"\" Transforms an input by replacing any word with one of its synonym.\n",
        "    \"\"\"\n",
        "  def _get_replacement_words(self, word):\n",
        "    ...\n",
        "        #and '_' not in lemma.name(): # avoid synonym if it contains the input word or multi-words\n",
        "        if word.lower() not in lemma.name().lower() and lemma.name().lower(\n",
        "        ) not in word.lower():\n",
        "          return [str(lemma.name())]  #[lemma.name()]\n",
        "    return [word]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPYClSCZ3cfT"
      },
      "source": [
        "Lets test our transformation on an input sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25sF6YK73rlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bceee0cd-5fca-4287-de46-47c694741996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence: I would like to buy some bitcoin\n",
            "\n",
            "Synonym:  bargain\n",
            "\n",
            "Adversarial example: I would like to bargain some bitcoin\n"
          ]
        }
      ],
      "source": [
        "syn_subs = Synonym_Substitution()  #Transformation object\n",
        "input_sample = \"I would like to buy some bitcoin\"  #input sample\n",
        "print('Input sentence: ' + input_sample)\n",
        "words = input_sample.split()  #tokenization\n",
        "\n",
        "#find a synonym for the 'buy' word\n",
        "synonym = ...\n",
        "print('\\nSynonym: ', synonym[0])\n",
        "input_sample = ...\n",
        "print('\\nAdversarial example: ' + input_sample)  #adversarial example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbwUWXZpfmUk"
      },
      "source": [
        "# Using Our Constraint\n",
        "\n",
        "This step designs a simple constraint component to allow our attack system to only substitute the Noun word in the transformation step. To do so, we need to specify Part of Speech (POS) tag for each word in the input text and only allow Nouns to be swapped. POS tagging is a popular NLP process which implies categorizing words within the input text in correspondence with a particular part of speech (such as noun, verb, and adjective), depending on the definition of the word and its context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYTmFSCW8QK3"
      },
      "outputs": [],
      "source": [
        "from textattack.constraints import Constraint\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "\n",
        "class NounConstraint(Constraint):\n",
        "  \"\"\" A constraint that ensures `transformed_text` only substitutes nouns from\n",
        "  `current_text` with other noun-based synonyms.\n",
        "    \"\"\"\n",
        "\n",
        "  def _check_constraint(self, transformed_text, current_text):\n",
        "    transformed_words = word_tokenize(transformed_text.text.lower())\n",
        "    current_words = word_tokenize(current_text.text.lower())\n",
        "\n",
        "    if len(transformed_words) != len(current_words):\n",
        "      # If the two sentences have a different number of words, then\n",
        "      # they definitely don't have the same Part of Speech Tag (POS) tag.\n",
        "      # In this case, the constraint is violated, and we return False.\n",
        "      return False\n",
        "    else:\n",
        "      # Here we compare all of the words, in order, to make sure that they match.\n",
        "      # If we find two words that don't match, this means a word was swapped\n",
        "      # between `current_text` and `transformed_text`. The word and its\n",
        "      # substitution must have a Noun POS tag to fulfill our constraint.\n",
        "      transformed_tags = ...\n",
        "      current_tags = ...\n",
        "      for i in range(len(transformed_words)):\n",
        "        if transformed_words[i] != current_words[i]:\n",
        "          if not (current_tags[i][1] == 'NOUN' and\n",
        "                  transformed_tags[i][1] == 'NOUN'):\n",
        "            return False\n",
        "\n",
        "      return True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnhreTOL67mZ"
      },
      "source": [
        "Lets test our constraint on two series of input sample pair:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nek-VsxF7Dwv"
      },
      "outputs": [],
      "source": [
        "from textattack.shared.attacked_text import AttackedText\n",
        "\n",
        "nounConstraint = NounConstraint(True)  #Constraint object\n",
        "\n",
        "input_sample1 = \"I would like to buy some apples\"  #input sample 1\n",
        "input_sample2 = \"I would like to bargain some apples\"  #input sample 2\n",
        "\n",
        "print('Input sentence1: ' + input_sample1)\n",
        "print('Input sentence2: ' + input_sample2)\n",
        "print(\n",
        "    'Constraint: ',\n",
        "    nounConstraint._check_constraint(...)\n",
        "\n",
        "input_sample1 = \"I would like to buy some apples\"  #input sample 1\n",
        "input_sample2 = \"I would like to buy some bananas\"  #input sample 2\n",
        "\n",
        "print('\\n\\nInput sentence1: ' + input_sample1)\n",
        "print('Input sentence2: ' + input_sample2)\n",
        "print(\n",
        "    'Constraint: ',\n",
        "    nounConstraint._check_constraint(...)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUyktipMcnyB"
      },
      "source": [
        "# Creating The Attack\n",
        "Let's use a greedy search method to find important word along with our transformation and constraint components as implemented in the previous steps. Greedy search initially scores transformations at all positions in the input text. Then it takes transformation(s) with the highest score(s) to fool the target model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAQqJuxP8c1p"
      },
      "outputs": [],
      "source": [
        "from textattack.search_methods import GreedySearch\n",
        "from textattack.constraints.pre_transformation import RepeatModification\n",
        "from textattack import Attack\n",
        "\n",
        "# We're going to use our Synonym_Substitution word swap class as the attack transformation.\n",
        "transformation = Synonym_Substitution()\n",
        "# We'll constrain Non-Noun substitutions\n",
        "constraints = [NounConstraint(False), RepeatModification()]\n",
        "# We'll use the Greedy search method\n",
        "search_method = GreedySearch()\n",
        "# Now, let's make the attack from the 4 components:\n",
        "attack = Attack(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgp_8iL7MQQw"
      },
      "source": [
        "# Utilizing The Attack\n",
        "Two classes of \"AttackArgs\" and \"Attacker\" are used to set our attack configuration and perform a desired attack on a specific dataset.\n",
        "\n",
        "The \"AttackArgs\" class represents arguments to be passed to Attacker, such as number of examples to attack, interval at which to save checkpoints, logging details. The \"Attacker\" class uses the designed attack to actually run the attacks, while also providing useful features such as parallel processing, saving/resuming from a checkpint, logging to files and stdout.\n",
        "\n",
        "The following example utilizes both \"AttackArgs\" and \"Attacker\" classes to run our designed attack on 20 samples from the AG News dataset:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EZg1wWUIr75"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm  # tqdm provides us a nice progress bar.\n",
        "from textattack.loggers import CSVLogger  # tracks a dataframe for us.\n",
        "from textattack import Attacker\n",
        "from textattack import AttackArgs\n",
        "\n",
        "# Attack 2 samples with CSV logging and checkpoint saved every 5 interval\n",
        "attack_args = AttackArgs(...)\n",
        "attacker = Attacker(...)\n",
        "attack_results = attacker.attack_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKGDKUqsLTRH"
      },
      "source": [
        "# Visualizing Our Attack Results\n",
        "\n",
        "`AttackResult` are been logged using a `CSVLogger`. This logger stores all attack results in a dataframe, which can be easily accessed and displayed."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC\n",
        "\n",
        "class Logger(ABC):\n",
        "    \"\"\"An abstract class for different methods of logging attack results.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def log_attack_result(self, result, examples_completed):\n",
        "        pass\n",
        "    def log_summary_rows(self, rows, title, window_id):\n",
        "        pass\n",
        "    def log_hist(self, arr, numbins, title, window_id):\n",
        "        pass\n",
        "    def log_sep(self):\n",
        "        pass\n",
        "    def flush(self):\n",
        "        pass\n",
        "    def close(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "jZX6uhoMoJPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from textattack.shared import AttackedText, logger\n",
        "\n",
        "class CSVLogger(Logger):\n",
        "    \"\"\"Logs attack results to a CSV.\"\"\"\n",
        "\n",
        "    def __init__(self, filename=\"results.csv\", color_method=\"file\"):\n",
        "        logger.info(f\"Logging to CSV at path {filename}\")\n",
        "        self.filename = filename\n",
        "        self.color_method = color_method\n",
        "        self.df = pd.DataFrame()\n",
        "        self._flushed = True\n",
        "\n",
        "    def log_attack_result(self, result):\n",
        "        original_text, perturbed_text = result.diff_color(self.color_method)\n",
        "        original_text = original_text.replace(\"\\n\", AttackedText.SPLIT_TOKEN)\n",
        "        perturbed_text = perturbed_text.replace(\"\\n\", AttackedText.SPLIT_TOKEN)\n",
        "        result_type = result.__class__.__name__.replace(\"AttackResult\", \"\")\n",
        "        row = {\n",
        "            \"original_text\": original_text,\n",
        "            \"perturbed_text\": perturbed_text,\n",
        "            \"original_score\": result.original_result.score,\n",
        "            \"perturbed_score\": result.perturbed_result.score,\n",
        "            \"original_output\": result.original_result.output,\n",
        "            \"perturbed_output\": result.perturbed_result.output,\n",
        "            \"ground_truth_output\": result.original_result.ground_truth_output,\n",
        "            \"num_queries\": result.num_queries,\n",
        "            \"result_type\": result_type,\n",
        "        }\n",
        "        self.df = self.df.append(row, ignore_index=True)\n",
        "        self._flushed = False\n",
        "\n",
        "\n",
        "    def flush(self):\n",
        "        self.df.to_csv(self.filename, quoting=csv.QUOTE_NONNUMERIC, index=False)\n",
        "        self._flushed = True"
      ],
      "metadata": {
        "id": "Z5kzeNaUQip8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkYw7yF9I7Hw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# increase colum width so we can actually read the examples\n",
        "pd.options.display.max_colwidth = 480\n",
        "\n",
        "logger = ...\n",
        "\n",
        "for result in attack_results:\n",
        "  logger.log_attack_result(result)\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "display(\n",
        "    HTML(logger.df[['original_text', 'perturbed_text']].to_html(escape=False)))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80a739244f134c5c8bee831f0a52d024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9c4e64bdf4a41d6980ffc28d0a29e41",
              "IPY_MODEL_14dda15a98044e46930667bd7afdbc50",
              "IPY_MODEL_3c3acc886a174238a39bcc2f54df10d1"
            ],
            "layout": "IPY_MODEL_3a702163f10645669e73a1c9661e8a19"
          }
        },
        "b9c4e64bdf4a41d6980ffc28d0a29e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97bde56b86f148e3afa13c94e573a38f",
            "placeholder": "​",
            "style": "IPY_MODEL_27c7200c9dae4da38494406e808d38ae",
            "value": "100%"
          }
        },
        "14dda15a98044e46930667bd7afdbc50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_082700d6e12843ce8eb952f2991db734",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a88ef7b99d924a60bbc3f15e5d227bb3",
            "value": 2
          }
        },
        "3c3acc886a174238a39bcc2f54df10d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ea639972b84778b545998ea617ce11",
            "placeholder": "​",
            "style": "IPY_MODEL_d84883c78de14be4aca6972fd5dd43a3",
            "value": " 2/2 [00:00&lt;00:00, 25.15it/s]"
          }
        },
        "3a702163f10645669e73a1c9661e8a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97bde56b86f148e3afa13c94e573a38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c7200c9dae4da38494406e808d38ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "082700d6e12843ce8eb952f2991db734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88ef7b99d924a60bbc3f15e5d227bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7ea639972b84778b545998ea617ce11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84883c78de14be4aca6972fd5dd43a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}