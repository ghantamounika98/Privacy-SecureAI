{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Xj2vw2PQBI"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShowLongYoung/SecurePrivateAILab/blob/solution/3_defend_cnn_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCBeUwVp9AS"
      },
      "source": [
        "# Defense with adversarial training\n",
        "\n",
        "In this section we will use adversarial training to harden our CNN against adversarial examples.\n",
        "\n",
        "In adversarial training the dataset get \"augmented\" with adversarial examples that are correctly labeled. This way the network learns that such pertubations are possible and can adapt to them.\n",
        "\n",
        "We will be using the IBM Adversarial Robustness Toolbox in this exercise. It offers a very easy-to-use implementation of adversarial training and a number of other defenses.\n",
        "https://github.com/IBM/adversarial-robustness-toolbox\n",
        "\n",
        "\n",
        "We start out by importing most of the modules and functions we will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rVt0vgHSPQBN"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-gpu==1.15.2 keras==2.2.3\n",
        "!pip install adversarial-robustness-toolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T21:30:14.009171Z",
          "start_time": "2021-09-20T21:30:12.996585Z"
        },
        "id": "SFCdbXWxp9AU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0065ea-5a1c-41ff-9d63-a7c2e820af17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "# most of our imports\n",
        "import warnings\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from art.estimators.classification import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract data with one and zero labels\n",
        "def exract_ones_and_zeroes( data, labels ):\n",
        "    data_zeroes = ...\n",
        "    data_ones = ...\n",
        "    x = np.vstack( ... )\n",
        "\n",
        "    x = x / 255.\n",
        "    print( x.shape )\n",
        "\n",
        "    labels_zeroes = ...\n",
        "    labels_ones = ...\n",
        "    y = np.append( ... )\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "Go0LWvghqyh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert image format to match the keras\n",
        "def convert_to_keras_image_format( x_train, x_test ):\n",
        "    if keras.backend.image_data_format( ) == 'channels_first':\n",
        "        x_train = x_train.reshape( ... )\n",
        "        x_test = x_test.reshape( ... )\n",
        "    else:\n",
        "        x_train = x_train.reshape( ... )\n",
        "        x_test = x_test.reshape( ... )\n",
        "\n",
        "    return x_train, x_test"
      ],
      "metadata": {
        "id": "JdKtunbxq8OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create cnn model\n",
        "def mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=2 ):\n",
        "    # define the classifier\n",
        "    clf = keras.Sequential( )\n",
        "    clf.add( Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[ 1: ] ) )\n",
        "    clf.add( Conv2D( 64, (3, 3), activation='relu' ) )\n",
        "    clf.add( MaxPooling2D( pool_size=(2, 2) ) )\n",
        "    clf.add( Dropout( 0.25 ) )\n",
        "    clf.add( Flatten( ) )\n",
        "    clf.add( Dense( 128, activation='relu' ) )\n",
        "    clf.add( Dropout( 0.5 ) )\n",
        "    clf.add( Dense( y_train.shape[ 1 ], activation='softmax' ) )\n",
        "\n",
        "    clf.compile( loss=keras.losses.categorical_crossentropy,\n",
        "                 optimizer='adam',\n",
        "                 metrics=[ 'accuracy' ] )\n",
        "\n",
        "    clf.fit( ... )\n",
        "    clf.summary( )\n",
        "    score = ...\n",
        "    print( 'Test loss:', ... )\n",
        "    print( 'Test accuracy:', ... )\n",
        "\n",
        "    return clf"
      ],
      "metadata": {
        "id": "njdK84cisuxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQb51r9Pp9AY"
      },
      "source": [
        "We start out by loading the data, preparing it and training our CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T21:30:17.234902Z",
          "start_time": "2021-09-20T21:30:14.010677Z"
        },
        "id": "Mi_KR9mVp9AZ"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# extract ones and zeroes data and labels\n",
        "x_train, y_train = ...\n",
        "x_test, y_test = ...\n",
        "\n",
        "# convert labels to one-hot codes\n",
        "y_train = ...\n",
        "y_test = ...\n",
        "\n",
        "# convert it to a format keras can work with\n",
        "x_train, x_test = convert_to_keras_image_format(...)\n",
        "\n",
        "# need to some setup so everything gets excturted in the same tensorflow session\n",
        "session = tf.Session( )\n",
        "keras.backend.set_session( session )\n",
        "\n",
        "# get and train our cnn\n",
        "clf = mnist_cnn_model( ... )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No-xgwJAp9Ae"
      },
      "source": [
        "We want to know how robust our model is against an attack. To do this we are calculating the `empirical robustness`. This is equivalent to computing the minimal perturbation that the attacker must introduce for a    successful attack. We are following the approach of Moosavi-Dezfooli et al. 2016 (paper link: https://arxiv.org/abs/1511.04599).\n",
        "\n",
        "The emperical robustness method supports two attacks at the moment.\n",
        "The `Fast Gradient Sign Method` and `Hop Skip and Jump`.\n",
        "\n",
        "You can use them by passing either `fgsm` or `hsj` as parameters.\n",
        "The default attack parameters are the following:\n",
        "```\n",
        "    \"fgsm\":{\"eps_step\": 0.1, \"eps_max\": 1., \"clip_min\": 0., \"clip_max\": 1.},\n",
        "    \"hsj\" {'max_iter': 50, 'max_eval': 10000, 'init_eval': 100, 'init_size': 100}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T21:30:17.864318Z",
          "start_time": "2021-09-20T21:30:17.237748Z"
        },
        "id": "SGO_xXwHp9Af"
      },
      "outputs": [],
      "source": [
        "  from art.metrics import empirical_robustness\n",
        "\n",
        "# wrap the model an calculte emperical robustnees\n",
        "wrapper = KerasClassifier(...)\n",
        "x_small = x_test[ :10 ]\n",
        "print( 'robustness of the undefended model',\n",
        "      empirical_robustness(...))\n",
        "print( 'robustness of the undefended model',\n",
        "      empirical_robustness(...))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkJT6D_p9Ai"
      },
      "source": [
        "Let's create an adversarial example and see how it looks.\n",
        "We want to know how to the model performs on adversarial exampels. Let's create adversarial examples out of the training set and see how the model does with it.\n",
        "\n",
        "Below you can the keyword arguments for the attack\n",
        "\n",
        "```\n",
        "norm=np.inf, eps=.3, eps_step=0.1, targeted=False, num_random_init=0, batch_size=1, minimal=False\n",
        "        \"\"\"\n",
        "        :param norm: The norm of the adversarial perturbation. Possible values: np.inf, 1 or 2.\n",
        "        :param eps: Attack step size (input variation)\n",
        "        :param eps_step: Step size of input variation for minimal perturbation computation\n",
        "        :param targeted: Indicates whether the attack is targeted (True) or untargeted (False)\n",
        "        :param num_random_init: Number of random initialisations within the epsilon ball. For random_init=0 starting at\n",
        "            the original input.\n",
        "        :param batch_size: Size of the batch on which adversarial samples are generated.\n",
        "        :param minimal: Indicates if computing the minimal perturbation (True). If True, also define `eps_step` for\n",
        "                        the step size and eps for the maximum perturbation.\n",
        "   \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T21:30:19.583064Z",
          "start_time": "2021-09-20T21:30:19.282468Z"
        },
        "id": "-anGrCjjp9Aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc237ef-fc44-4772-ead2-1d47968d978a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class prediction for the adversarial sample: [[0.8604998  0.13950023]]\n",
            "accuracy on adversarial examples:\n",
            "0.9475\n"
          ]
        }
      ],
      "source": [
        "# create an adversarial example with fgsm\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "fgsm = FastGradientMethod(...)\n",
        "x_adv = fgsm.generate(...)\n",
        "print( 'class prediction for the adversarial sample:',\n",
        "       clf.predict(...) )\n",
        "\n",
        "# create adversarial examples for the all of the set\n",
        "x_test_adv = ...\n",
        "print( 'accuracy on adversarial examples:' )\n",
        "print( wrapper._model.evaluate( ... )[ 1 ] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhEY7Iagp9Aw"
      },
      "source": [
        "## Adversarial Training\n",
        "\n",
        "Let's create a new untrained model with the same architecture that we have been using so far.\n",
        "\n",
        "We will train the model using adversarial training framework. The idea is very simple:\n",
        "\n",
        "1.   Train the model for 1 epoch\n",
        "2.   Create adversarial examples using FGSM\n",
        "3.   Enhance training data by mixing it with the adversarial examples. (Only mix in the adversarial examples created in this iteartion)\n",
        "4.   Goto 1\n",
        "\n",
        "We will be using the FGSM attack from `art` this time.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T21:30:22.768988Z",
          "start_time": "2021-09-20T21:30:19.584820Z"
        },
        "id": "KfHrX6WftGOo"
      },
      "outputs": [],
      "source": [
        "# create a new untrained model and wrap it\n",
        "new_model = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=0 )\n",
        "defended_model = KerasClassifier(...)\n",
        "# define the attack we are using\n",
        "fgsm = ...\n",
        "\n",
        "# parameters\n",
        "epochs = 5 # number of iterations that we will perform training for\n",
        "ratio = .5  # ratio of the test set that will get turned into adversarial examples\n",
        "            # each iteration\n",
        "\n",
        "\n",
        "# some helpers\n",
        "idx = np.arange( x_train.shape[ 0 ], dtype=np.int )\n",
        "\n",
        "# create varialbes to hold the training data.\n",
        "# for now it is just the normal training data. we'll mix in the\n",
        "# adversarial examples in later\n",
        "x_train_enhanced = x_train\n",
        "y_train_enhanced = y_train\n",
        "\n",
        "\n",
        "for i in range( epochs ):\n",
        "  # train model for one epoch\n",
        "  defended_model.fit( ... )\n",
        "\n",
        "  # shuffle\n",
        "  np.random.shuffle( idx )\n",
        "  # pick the subest of the train data to turn into adverarial examples\n",
        "  x_train_ = x_train[ idx[ int( idx.shape[ 0 ] * ratio ) : ]  ]\n",
        "  y_train_ = y_train[ idx[ int( idx.shape[ 0 ] * ratio ) : ]  ]\n",
        "\n",
        "  # create adversarial examples\n",
        "  x_adv = ...\n",
        "  # add the adversarial examples to the training data\n",
        "  x_train_enhanced = np.vstack( ... )\n",
        "  y_train_enhanced = np.vstack( ( ... )\n",
        "\n",
        "# training is done. let's evaulate the performance on the test set\n",
        "# and adversarial examples\n",
        "acc = defended_model._model.evaluate( ... )[ 1 ]\n",
        "print( 'acc on the test data: ', acc )\n",
        "\n",
        "# and now on adversarial examples\n",
        "x_test_adv = ...\n",
        "acc =  ...\n",
        "print( 'accuracy on adversarial examples: ', acc )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhTCRfbCr6iq"
      },
      "source": [
        "To use the adversarial training that comes with `art` we need to pass our wrapped model to an `AdversarialTrainer` instance. The `AdversarialTrainer` also needs an instance of the attack that will be used to create the adversarial examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T21:30:23.893487Z",
          "start_time": "2021-09-20T21:30:22.770668Z"
        },
        "id": "uxQZLbgBp9Ay"
      },
      "outputs": [],
      "source": [
        "from art.defences.trainer import AdversarialTrainer\n",
        "\n",
        "# get a new untrained model and warp it\n",
        "new_model = mnist_cnn_model( ... )\n",
        "defended_model = KerasClassifier(...)\n",
        "# define the attack we are using\n",
        "fgsm = ...\n",
        "\n",
        "# define the adversarial trainer and train the new network\n",
        "adversarial_tranier = AdversarialTrainer(...)\n",
        "adversarial_tranier.fit(...)\n",
        "\n",
        "# evaluate how good our model is\n",
        "defended_model._model.evaluate(...)\n",
        "\n",
        "# and now on adversarial examples\n",
        "x_test_adv = ...\n",
        "acc =  ...\n",
        "print( 'loss and accuracy on adversarial examples: ', acc )\n",
        "\n",
        "# calculate the empiracal robustness\n",
        "print( 'robustness of the defended model',\n",
        "      empirical_robustness(...) )\n",
        "\n",
        "x_adv = ...\n",
        "print( 'class prediction for the adversarial sample:',\n",
        "       clf.predict( ... )\n",
        "     )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}