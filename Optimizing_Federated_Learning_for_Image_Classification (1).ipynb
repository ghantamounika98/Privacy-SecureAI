{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6ezMj-QA8bb"
      },
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import collections\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 and CIFAR-100 datasets\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "(x_train100, y_train100), (x_test100, y_test100) = datasets.cifar100.load_data()\n"
      ],
      "metadata": {
        "id": "IjY4snr0uyDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the data\n",
        "def preprocess_images(images):\n",
        "    images = images.astype('float32')\n",
        "    images = (images - 127.5) / 127.5  # Normalize the pixel values\n",
        "    return tf.convert_to_tensor(images)\n",
        "\n",
        "x_train = preprocess_images(x_train)\n",
        "x_test = preprocess_images(x_test)\n",
        "\n",
        "x_train100 = preprocess_images(x_train100)\n",
        "x_test100 = preprocess_images(x_test100)\n"
      ],
      "metadata": {
        "id": "mKXUCq9xwcoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the CNN model architecture\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "08djLjpOw2a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Federated Averaging algorithm for aggregating model updates\n",
        "def federated_averaging(global_weights, client_weights, num_clients):\n",
        "    total_weights = np.zeros_like(global_weights)\n",
        "    for client_weight in client_weights:\n",
        "        total_weights += client_weight\n",
        "    global_weights = total_weights / num_clients\n",
        "    return global_weights"
      ],
      "metadata": {
        "id": "fq3aE7Vwz2mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the centralized server\n",
        "def server(model, num_clients, rounds, train_data):\n",
        "    for i in range(rounds):\n",
        "        # Initialize the client weights\n",
        "        client_weights = [model.get_weights() for i in range(num_clients)]\n",
        "\n",
        "        # Send the client weights to each client\n",
        "        for j in range(num_clients):\n",
        "            # Train the client model\n",
        "            client_model = create_model()\n",
        "            client_model.set_weights(client_weights[j])\n",
        "            client_model.fit(train_data[j][0], train_data[j][1], epochs=1, verbose=0)\n",
        "\n",
        "            # Compute the client model weights\n",
        "            client_weights[j] = client_model.get_weights()\n",
        "\n",
        "        # Aggregate the client weights using Federated Averaging\n",
        "        model.set_weights(federated_averaging(model.get_weights(), client_weights, num_clients))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "tH2nrnoyz7w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the clients\n",
        "def clients(model, num_clients, train_data):\n",
        "    for i in range(num_clients):\n",
        "        # Train the client model\n",
        "        client_model = create_model()\n",
        "        client_model.set_weights(model.get_weights())\n",
        "        client_model.fit(train_data[i][0], train_data[i][1], epochs=1, verbose=0)\n",
        "\n",
        "        # Compute the client model weights\n",
        "        client_weights = client_model.get_weights()\n",
        "\n",
        "        # Send the client weights back to the server\n",
        "        yield client_weights"
      ],
      "metadata": {
        "id": "x_bhK7Xd0AS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the CIFAR-10 and CIFAR-100 datasets\n",
        "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
        "cifar100 = tf.keras.datasets.cifar100.load_data()\n",
        "\n",
        "cifar10_train, cifar10_test = cifar10\n",
        "cifar100_train, cifar100_test = cifar100\n",
        "\n",
        "cifar10_train = (cifar10_train[0] / 255.0, tf.keras.utils.to_categorical(cifar10_train[1]))\n",
        "cifar10_test = (cifar10_test[0] / 255.0, tf.keras.utils.to_categorical(cifar10_test[1]))\n",
        "cifar100_train = (cifar100_train[0] / 255.0, tf.keras.utils.to_categorical(cifar100_train[1]))\n",
        "cifar100_test = (cifar100_test[0] / 255.0, tf.keras.utils.to_categorical(cifar100_test[1]))\n"
      ],
      "metadata": {
        "id": "RuzWqt350Ry4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of clients and training rounds\n",
        "NUM_CLIENTS = 500\n",
        "NUM_CLIENTS_TEST = 100\n",
        "NUM_ROUNDS = 50\n",
        "NUM_CLIENTS_PER_ROUND = 10"
      ],
      "metadata": {
        "id": "FQHYoMII02Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 and CIFAR-100 datasets\n",
        "cifar10_train, cifar10_test = tf.keras.datasets.cifar10.load_data()\n",
        "cifar100_train, cifar100_test = tf.keras.datasets.cifar100.load_data()\n"
      ],
      "metadata": {
        "id": "1P3CyvPV1FQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to preprocess the data\n",
        "def preprocess_data(raw_x, raw_y):\n",
        "    x = tf.cast(raw_x, tf.float32) / 255.0\n",
        "    y = tf.cast(raw_y, tf.int32)\n",
        "    return {'image': x}, y\n",
        "\n",
        "# Create the preprocessed datasets\n",
        "preprocessed_train_data = {\n",
        "    'cifar10': tf.data.Dataset.from_tensor_slices(cifar10_train).map(preprocess_data),\n",
        "    'cifar100': tf.data.Dataset.from_tensor_slices(cifar100_train).map(preprocess_data)\n",
        "}\n",
        "\n",
        "preprocessed_test_data = {\n",
        "    'cifar10': tf.data.Dataset.from_tensor_slices(cifar10_test).map(preprocess_data),\n",
        "    'cifar100': tf.data.Dataset.from_tensor_slices(cifar100_test).map(preprocess_data)\n",
        "}\n"
      ],
      "metadata": {
        "id": "dxqcXx5W1L93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to evaluate the model on a dataset\n",
        "def evaluate_model(model, dataset):\n",
        "    loss = tf.keras.metrics.Mean()\n",
        "    accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "    for x, y in dataset:\n",
        "        y_pred = model(x)['output']\n",
        "        loss(y, y_pred)\n",
        "        accuracy(y, y_pred)\n",
        "\n",
        "    return {'loss': loss.result().numpy(), 'accuracy': accuracy.result().numpy()}\n"
      ],
      "metadata": {
        "id": "0ymBrpRm1geO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to create the model for each client\n",
        "def model_fn():\n",
        "    model = create_model()\n",
        "    return tff.learning.from_keras_model(\n",
        "        model,\n",
        "        input_spec=preprocessed_train_data['cifar10'].element_spec,\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "# Define the federated averaging process\n",
        "    fed_avg = tff.learning.build_federated_averaging_process(\n",
        "    model_fn=model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.1),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\n",
        ")\n"
      ],
      "metadata": {
        "id": "K16bcXOQ1nK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_federated_model(train_data, test_data, num_clients, num_rounds, batch_size, learning_rate):\n",
        "# Create the centralized model\n",
        "  global_model = create_cifar10_model() if isinstance(train_data.element_spec, tuple) else create_cifar100_model()\n",
        "  global_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n"
      ],
      "metadata": {
        "id": "U0tG8jjL3gXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Initialize the server state\n",
        "state = fed_avg.initialize()\n",
        "\n",
        "# Train the model using federated learning\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    # Sample a subset of clients to participate in this round\n",
        "    sampled_clients = np.random.choice(client_ids, NUM_CLIENTS_PER_ROUND, replace=False)\n",
        "\n",
        "    # Create a list of federated datasets for the selected clients\n",
        "    federated_train_data = [preprocessed_train_data.create_tf_dataset_for_client(client) for client in sampled_clients]\n",
        "\n",
        "    # Train on the selected clients' data\n",
        "    state, metrics = fed_avg.next(state, federated_train_data)\n",
        "\n",
        "    # Evaluate the model on the test data after every 10 rounds\n",
        "    if (round_num + 1) % 10 == 0:\n",
        "        test_metrics = evaluate_model(model, preprocessed_test_data)\n",
        "        print(f\"Round {round_num + 1}, Test metrics: {test_metrics}\")\n"
      ],
      "metadata": {
        "id": "wFXKkErx0hFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Partition the data across clients\n",
        "def partition_data(images, labels, num_clients):\n",
        "    \"\"\"Partition the data across the given number of clients.\"\"\"\n",
        "    num_items_per_client = len(images) // num_clients\n",
        "    partitioned_images = collections.defaultdict(list)\n",
        "    partitioned_labels = collections.defaultdict(list)\n",
        "    for i in range(num_clients):\n",
        "        for j in range(num_items_per_client):\n",
        "            idx = i * num_items_per_client + j\n",
        "            partitioned_images[i].append(images[idx])\n",
        "            partitioned_labels[i].append(labels[idx])\n",
        "    return partitioned_images, partitioned_labels\n",
        "\n",
        "num_clients = 500\n",
        "x_train_partitions, y_train_partitions = partition_data(x_train, y_train, num_clients)\n",
        "\n",
        "num_clients100 = 100\n",
        "x_train_partitions100, y_train_partitions100 = partition_data(x_train100, y_train100, num_clients100)\n"
      ],
      "metadata": {
        "id": "YoQvI4McxAE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the federated learning algorithm"
      ],
      "metadata": {
        "id": "JYJRKM1kxLCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}