{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc1d8c5xSxPY"
      },
      "source": [
        "!pip install opacus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iDtYlKCS1bS"
      },
      "source": [
        "from opacus import PrivacyEngine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fXINQJyCQwC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__wy5V8HEuYp"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.fc1 = nn.Linear(2048, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        # self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        # self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        # self.conv2_drop = nn.Dropout2d()\n",
        "        # self.fc1 = nn.Linear(320, 50)\n",
        "        # self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # fill the forward function\n",
        "        x = self.conv1(x)\n",
        "        ...\n",
        "\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "        # x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        # x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        # x = x.view(-1, 320)\n",
        "        # x = F.relu(self.fc1(x))\n",
        "        # x = F.dropout(x, training=self.training)\n",
        "        # x = self.fc2(x)\n",
        "        # return F.log_softmax(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDgMzg7CQ0kb"
      },
      "source": [
        "\n",
        "# IID case: all the clients have images of all the classes\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "num_clients = 10\n",
        "num_selected = 5\n",
        "Epoch = 5\n",
        "iter_per_client = 10\n",
        "batch_size = 32\n",
        "\n",
        "pre_delta=1e-5\n",
        "momentum=0.5\n",
        "pre_lr=1e-2\n",
        "EPSILON = 50.0\n",
        "\n",
        "MAX_GRAD=1.5\n",
        "NOISE_MUL=1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73vre2nBFUy5"
      },
      "source": [
        "def client_update(client_model, optimizer, train_loader, privacy_engine, epoch=5, delta=1e-5):\n",
        "    model.train()\n",
        "    criterion = ...\n",
        "\n",
        "    for e in range(epoch):\n",
        "        losses = []\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(\"cuda\")\n",
        "            target = target.to(\"cuda\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # code of how to compute the loss\n",
        "            output = ...\n",
        "            loss = ...\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            losses.append(loss.item()) ###########\n",
        "    # fill this blank\n",
        "    epsilon = ...\n",
        "    print(f\"[client_i]\\t\"\n",
        "                  f\"Train Epoch: {e} \\t\"\n",
        "                  f\"Loss: {sum(losses)/len(losses):.4f} \"\n",
        "                  f\"(ε = {epsilon}, δ = {delta})\")\n",
        "    # print('Epsilon={}'.format(epsilon))\n",
        "\n",
        "    return loss.item(), epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def server_aggregate(global_model, client_models):\n",
        "    global_dict = global_model.state_dict()\n",
        "    for k in global_dict.keys():\n",
        "        # stack all clients k-th state to generate the global k-th state\n",
        "        global_dict[k] = torch.stack([...], 0).mean(0)\n",
        "    global_model.load_state_dict(global_dict)\n",
        "    for model in client_models:\n",
        "        # download the global model to each client\n",
        "        model.load_state_dict(...)"
      ],
      "metadata": {
        "id": "DzwUyS4C1g7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqpi21ZRQyJ5"
      },
      "source": [
        "def test(global_model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            # fill the blank\n",
        "            output = ...\n",
        "            test_loss += ...  # sum up batch loss\n",
        "            pred = ... # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc = correct / len(test_loader.dataset)\n",
        "\n",
        "    return test_loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7KyzpdBQ71v"
      },
      "source": [
        "# Creating decentralized datasets\n",
        "# download dataset\n",
        "traindata = datasets.MNIST('./data', train=True, download=True,\n",
        "                       transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "                       )\n",
        "\n",
        "# split dataset\n",
        "# fill this blank\n",
        "traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / ... ) for _ in range(num_clients)])\n",
        "# train_loaders\n",
        "train_loader_ls = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "        ), batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32KdvSeoUunh"
      },
      "source": [
        "client_models, optimizers, DP_dataloader_ls, privacy_engine_ls = [], [], [], []\n",
        "\n",
        "for client in range(num_clients):\n",
        "    model=Net().to(\"cuda\")\n",
        "\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=pre_lr)\n",
        "\n",
        "    data=train_loader_ls[client]\n",
        "\n",
        "    privacy_engine = PrivacyEngine()\n",
        "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
        "        # fill these parameters\n",
        "        ...\n",
        "    )\n",
        "\n",
        "    client_models.append(...)\n",
        "    # dataloaders.append(dataloader)\n",
        "    optimizers.append(...)\n",
        "    privacy_engine_ls.append(...)\n",
        "    DP_dataloader_ls.append(...)\n",
        "    # print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdcGdw9URBAJ"
      },
      "source": [
        "# Instantiate models and optimizers\n",
        "\n",
        "global_model = client_models[0]\n",
        "\n",
        "# client_models = [Net().cuda() for _ in range(num_selected)]\n",
        "# for model in client_models:\n",
        "#     model_params=global_model.state_dict()\n",
        "#     model.load_state_dict(model_params)\n",
        "\n",
        "# opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
        "\n",
        "# Runnining FL\n",
        "test_acc, test_losses, epsilon = [], [], []\n",
        "\n",
        "for r in range(Epoch):\n",
        "    # select random clients\n",
        "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
        "\n",
        "    # client update\n",
        "    loss = 0\n",
        "    eps_ls=[]\n",
        "    for i in range(num_selected):\n",
        "        # fill the parameters\n",
        "        loss, eps= client_update(...)\n",
        "\n",
        "        loss+=loss\n",
        "        eps_ls.append(eps)\n",
        "\n",
        "    # serer aggregate\n",
        "    server_aggregate(global_model, client_models)\n",
        "    test_loss, acc = test(...)\n",
        "\n",
        "    test_acc.append(acc)\n",
        "    test_losses.append(test_loss)\n",
        "    epsilon.append(max(eps_ls))\n",
        "    print('%d-th round' % r)\n",
        "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f | epsilon: %0.3f' % (loss / num_selected, test_loss, acc, max(eps_ls)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coqF7vv5fc6D"
      },
      "source": [
        "from pylab import plt\n",
        "x = [i+1 for i in range(Epoch)]\n",
        "plt.plot(x,test_acc,label='Accuracy')\n",
        "plt.plot(x,test_losses,label='Loss')\n",
        "plt.title(\"Accuracy vs Loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('%')\n",
        "plt.xticks(x)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# plt.savefig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To find the effect of Hyperparameters on the performance of DPFL"
      ],
      "metadata": {
        "id": "plV_S3-qyhad"
      }
    }
  ]
}