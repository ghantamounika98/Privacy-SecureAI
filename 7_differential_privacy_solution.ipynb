{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShowLongYoung/SecurePrivateAILab/blob/solution/7_differential_privacy_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "collapsed": false,
        "id": "AxUbFNvLuYUY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3G_Tg5ONqOK"
      },
      "source": [
        "# Privacy Preserving Machine Learning\n",
        "\n",
        "First things first. Let's run the package installations. They take quite a while.\n",
        "\n",
        "Change the Runtime of this Notebook to GPU first. Otherwise it will be pretty slow.\n",
        "\n",
        "To do so go to Runtime -> Change Runtime Type and change it to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rImgnfa-h99n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "e70bdbf8-da70-4c5e-a78a-ab143769041a"
      },
      "source": [
        "!pip install syft==0.2.9 keras==2.2.3 tensorflow_privacy==0.2.2\n",
        "\n",
        "# !git clone https://github.com/OpenMined/PySyft.git\n",
        "# !pip install -e PySyft\n",
        "# !pip install tensorflow_federated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'PySyft' already exists and is not an empty directory.\n",
            "Obtaining file:///content/PySyft\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (1.1.2)\n",
            "Requirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (1.4.1)\n",
            "Requirement already satisfied: flask-socketio~=4.2.1 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (4.2.1)\n",
            "Requirement already satisfied: lz4~=3.0.2 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (3.0.2)\n",
            "Requirement already satisfied: syft-proto~=0.2.9.a2 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (0.2.9a2)\n",
            "Requirement already satisfied: websocket-client~=0.57.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (0.57.0)\n",
            "Requirement already satisfied: tornado==4.5.3 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (4.5.3)\n",
            "Requirement already satisfied: tblib~=1.6.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (1.6.0)\n",
            "Requirement already satisfied: requests~=2.22.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (2.22.0)\n",
            "Requirement already satisfied: torchvision~=0.5.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (0.5.0)\n",
            "Requirement already satisfied: numpy~=1.18.1 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (1.18.2)\n",
            "Requirement already satisfied: torch~=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (1.4.0)\n",
            "Requirement already satisfied: phe~=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (1.4.0)\n",
            "Requirement already satisfied: websockets~=8.1.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (8.1)\n",
            "Requirement already satisfied: Pillow~=6.2.2 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (6.2.2)\n",
            "Requirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.4) (1.0.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft==0.2.4) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft==0.2.4) (7.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft==0.2.4) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft==0.2.4) (1.0.1)\n",
            "Requirement already satisfied: python-socketio>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio~=4.2.1->syft==0.2.4) (4.5.1)\n",
            "Requirement already satisfied: protobuf>=3.11.1 in /usr/local/lib/python3.6/dist-packages (from syft-proto~=0.2.9.a2->syft==0.2.4) (3.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client~=0.57.0->syft==0.2.4) (1.12.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft==0.2.4) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft==0.2.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft==0.2.4) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft==0.2.4) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask~=1.1.1->syft==0.2.4) (1.1.1)\n",
            "Requirement already satisfied: python-engineio>=3.9.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=4.3.0->flask-socketio~=4.2.1->syft==0.2.4) (3.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.1->syft-proto~=0.2.9.a2->syft==0.2.4) (46.1.3)\n",
            "Installing collected packages: syft\n",
            "  Found existing installation: syft 0.2.4\n",
            "    Can't uninstall 'syft'. No files were found to uninstall.\n",
            "  Running setup.py develop for syft\n",
            "Successfully installed syft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K1fejzQOHlv"
      },
      "source": [
        "Next we'll get our usual boilerplat code out of the way. Data loading, splitting, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orh1mHXqOh0u"
      },
      "source": [
        "Load our data set and split it into test and training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeT48vu3PmAa"
      },
      "source": [
        "## Differential Privacy\n",
        "\n",
        "Below we will train a model perform malware detection. Image classification on the MNIST data. will train it using Differantially Private SGD optimimizer.\n",
        "\n",
        "How does the privacy budget `epsilon` change when you tweak the parameters of the optimizer? How does it influence accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv_M25D9HYeS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "c4c2b443-d85c-44b5-dec3-d4b114f89d71"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
        "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPGradientDescentGaussianOptimizer\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
        "\n",
        "mnist_x_train = mnist_x_train.astype( np.float32 ) / 255\n",
        "mnist_x_test = mnist_x_test.astype( np.float32 ) / 255\n",
        "\n",
        "mnist_x_train = mnist_x_train.reshape( -1, 28, 28, 1)\n",
        "mnist_x_test = mnist_x_test.reshape( -1, 28, 28, 1)\n",
        "\n",
        "\n",
        "mnist_y_train = keras.utils.to_categorical( mnist_y_train )\n",
        "mnist_y_test = keras.utils.to_categorical( mnist_y_test )\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 250\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add( tf.keras.layers.Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=mnist_x_train.shape[ 1: ]  ) )\n",
        "model.add( tf.keras.layers.MaxPooling2D( pool_size=(2, 2) ) )\n",
        "model.add( tf.keras.layers.Conv2D( 64, kernel_size=(3, 3), activation='relu' ) )\n",
        "model.add( tf.keras.layers.Flatten() )\n",
        "model.add( tf.keras.layers.Dense( 128, activation='relu' ) )\n",
        "model.add( tf.keras.layers.Dense( 10, activation='softmax' ) )\n",
        "\n",
        "\n",
        "optimizer = DPGradientDescentGaussianOptimizer(\n",
        "    l2_norm_clip=1.5,\n",
        "    noise_multiplier=1.3,\n",
        "    num_microbatches=250,\n",
        "    learning_rate=0.25)\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy( from_logits=True, reduction=tf.losses.Reduction.NONE )\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "model.fit(mnist_x_train, mnist_y_train,\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE)\n",
        "\n",
        "print( 'test acc:', model.evaluate( mnist_x_test, mnist_y_test, batch_size=250 ) )\n",
        "\n",
        "eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=60000, batch_size=250, noise_multiplier=1.3, epochs=15, delta=1e-5)\n",
        "print( 'epsilon: ', eps )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3624 - accuracy: 0.0988\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3625 - accuracy: 0.0986\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3625 - accuracy: 0.0986\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3625 - accuracy: 0.0986\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3625 - accuracy: 0.0986\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3625 - accuracy: 0.0986\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3625 - accuracy: 0.0986\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3625 - accuracy: 0.0986\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3625 - accuracy: 0.0986\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 2.3625 - accuracy: 0.0986\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2.3653 - accuracy: 0.0958\n",
            "test acc: [2.365349054336548, 0.0957999974489212]\n",
            "DP-SGD with sampling rate = 0.417% and noise_multiplier = 1.3 iterated over 3600 steps satisfies differential privacy with eps = 1.18 and delta = 1e-05.\n",
            "The optimal RDP order is 17.0.\n",
            "epsilon:  (1.1799006739827, 17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlR0Dnw8HeyJ"
      },
      "source": [
        "# Pate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWbpCjGGHgKE"
      },
      "source": [
        "First we need to split up the data and train the teachers. For simplicty we will work with 3 teachers and a small amount of data.\n",
        "\n",
        "\n",
        "We are going to split the data into 4 partions of 500 instances each. 3 partions for the teachers and one for the students.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaZNmdzeICtE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "00b29319-ea31-447d-a38a-4dd52aafdd16"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "n_instances = 500\n",
        "n_teachers = 3\n",
        "\n",
        "# load data and transform it\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype( float ) / 255.\n",
        "x_test = x_test.astype( float ) / 255.\n",
        "\n",
        "x_train = x_train.reshape( -1, 28, 28, 1)\n",
        "x_test = x_test.reshape( -1, 28, 28, 1)\n",
        "\n",
        "y_train = keras.utils.to_categorical( y_train )\n",
        "y_test = keras.utils.to_categorical( y_test )\n",
        "\n",
        "# shuffle data\n",
        "idx = np.arange( len( x_train ) )\n",
        "np.random.shuffle( idx )\n",
        "x_train = x_train[ idx ]\n",
        "y_train = y_train[ idx ]\n",
        "\n",
        "# gather the teacher data\n",
        "teacher_data_x = [ x_train[ i * n_instances : ( i + 1 ) * n_instances ] for i in range( n_teachers ) ]\n",
        "teacher_data_y = [ y_train[ i * n_instances : ( i + 1 ) * n_instances ] for i in range( n_teachers ) ]\n",
        "\n",
        "# gather the student data\n",
        "student_data_x = x_train[ n_teachers * n_instances : ( n_teachers + 1 ) * n_instances ]\n",
        "student_data_y = y_train[ n_teachers * n_instances : ( n_teachers + 1 ) * n_instances ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N45SSQDAMwaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "91f38a9d-325f-43cf-def3-a826f8a55269"
      },
      "source": [
        "# train the teacher models\n",
        "def get_model():\n",
        "  model = keras.models.Sequential()\n",
        "  model.add( keras.layers.Conv2D( 32, 3, 2, activation='relu', input_shape=x_train.shape[ 1: ] ) )\n",
        "  model.add( keras.layers.MaxPooling2D( ) )\n",
        "  model.add( keras.layers.Conv2D( 16, 3, 2, activation='relu' ) )\n",
        "  model.add( keras.layers.Flatten() )\n",
        "  model.add( keras.layers.Dense(32, activation='relu') )\n",
        "  model.add( keras.layers.Dense(10, activation='softmax') )\n",
        "\n",
        "  model.compile( optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'] )\n",
        "\n",
        "  return model\n",
        "\n",
        "# list of teacher models\n",
        "teacher_models = [ get_model() for _ in range( n_teachers ) ]\n",
        "\n",
        "# train teacher models\n",
        "for i, (model, x, y) in enumerate( zip( teacher_models, teacher_data_x, teacher_data_y ) ):\n",
        "  print( 'teacher', i )\n",
        "  model.fit( x, y, epochs=16, verbose=0 )\n",
        "  print( 'test accuracy:', model.evaluate( x_test, y_test, verbose=0 )[ 1 ] )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "teacher 0\n",
            "test accuracy: 0.8320000171661377\n",
            "teacher 1\n",
            "test accuracy: 0.8119999766349792\n",
            "teacher 2\n",
            "test accuracy: 0.7914000153541565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCkzvxlER6EQ"
      },
      "source": [
        "## Train the student model\n",
        "\n",
        "To train the student model we need to label the students training data using the teacher models. We'll use a majority voting with added noises to determine the label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-GHRrstSuAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "23dd2838-71b5-4430-b6a0-ca5f3543d46f"
      },
      "source": [
        "# label the data\n",
        "labels = [ teacher.predict( student_data_x ) for teacher in teacher_models ]\n",
        "\n",
        "# preform the voting\n",
        "votes = np.zeros( ( student_data_x.shape[ 0 ], 10 ), dtype=np.float )\n",
        "for i in range( len( student_data_x ) ):\n",
        "  for j in range( n_teachers ):\n",
        "    label = np.argmax( labels[ j ][ i ] )\n",
        "    votes[ i, label ] += 1\n",
        "  # add the noise per class\n",
        "  for j in range( 10 ):\n",
        "    votes[ i, j ] += np.random.laplace(loc=0.0, scale=5 )\n",
        "\n",
        "student_data_y = keras.utils.to_categorical( np.argmax( votes, axis=1 ) )\n",
        "\n",
        "# train model\n",
        "student_model = get_model()\n",
        "print( 'training student model' )\n",
        "student_model.fit( x, y, epochs=16, verbose=0 )\n",
        "print( 'test accuracy:', student_model.evaluate( student_data_x, student_data_y, verbose=0 )[ 1 ] )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training student model\n",
            "test accuracy: 0.15199999511241913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXIAPzblUyOJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "623c57fb-93de-4bc0-9ed2-06a37ef6660b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# privacy analysis\n",
        "from syft.frameworks.torch.dp import pate\n",
        "\n",
        "\n",
        "teacher_preds = np.argmax( np.array( labels ), axis=2 )\n",
        "print( teacher_preds.shape )\n",
        "\n",
        "data_dep_eps, data_indep_eps = pate.perform_analysis( teacher_preds=teacher_preds,\n",
        "                                                      indices=np.argmax( votes, axis=1 ),\n",
        "                                                      noise_eps=0.2,\n",
        "                                                      delta=1/1500\n",
        "                                                     )\n",
        "\n",
        "print(data_dep_eps, data_indep_eps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 500)\n",
            "87.3132203870893 87.31322038709031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "10qxtrB0uYUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's more. Try by yourself with PyTorch\n",
        "\n",
        "https://opacus.ai/tutorials/building_image_classifier\n",
        "\n",
        "[Opacus](https://github.com/pytorch/opacus) is a library that enables training PyTorch models with differential privacy. It supports training with minimal code changes required on the client, has little impact on training performance and allows the client to online track the privacy budget expended at any given moment.\n",
        "\n",
        "Just click\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/pytorch/opacus/blob/main/tutorials/building_image_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "It comes from\n",
        "https://github.com/pytorch/opacus/blob/main/tutorials/building_image_classifier.ipynb\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "fuRkWsB1uYUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And another report\n",
        "\n",
        "https://github.com/erinqhu/differential-privacy-PATE/blob/master/PATE_analysis.ipynb\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/erinqhu/differential-privacy-PATE/blob/master/PATE_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hp6lhz1-uYUe"
      }
    }
  ]
}